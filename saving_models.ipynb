{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting models for use on client-side apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My model was using transfer learning from Resnet-50. So, I will need to either\n",
    "- create a model with both, or\n",
    "- extract both models separately and use the predictions of one in the other\n",
    "\n",
    "Architecturally, it makes more sense to go the later way, because then the last layer can be easily replaced while using this for other apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the saved weights for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/akshata/.conda/envs/dog-project/lib/python3.6/site-packages/keras/models.py:240: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 500)               1024500   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 133)               66633     \n",
      "=================================================================\n",
      "Total params: 1,091,133.0\n",
      "Trainable params: 1,091,133.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "base_resnet = load_model('./keras_models/base_resnet.hdf5')\n",
    "last_layers_model = load_model('./keras_models/weights.extra_layers.hdf5')\n",
    "last_layers_model.summary()\n",
    "\n",
    "## ignore the warning for base_resnet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dogs: 133\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "dog_names = np.load('./labels/dog_names.npy')\n",
    "print('Number of dogs:', len(dog_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### function converts an image path into a tensor that can be input into the resnet model\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image    \n",
    "import numpy as np\n",
    "\n",
    "def predict_breed(img_path):\n",
    "    tensor = path_to_tensor(img_path)\n",
    "    bottleneck_feature = base_resnet.predict(preprocess_input(tensor))\n",
    "    predicted_vector = last_layers_model.predict(bottleneck_feature)\n",
    "    return dog_names[np.argmax(predicted_vector)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Affenpinsche'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_breed('./dogImages/001.Affenpinscher/Affenpinscher_00038.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Android\n",
    "\n",
    "Deploying to android requires a .pb format. Use the following function, to convert your model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.python.framework import graph_util, graph_io\n",
    "from tensorflow.python.tools import import_pb_to_tensorboard\n",
    "\n",
    "def keras_to_tensorflow(keras_model, \n",
    "        output_dir, \n",
    "        model_name,\n",
    "        out_prefix=\"output_\", \n",
    "        log_tensorboard=True):\n",
    "\n",
    "    if os.path.exists(output_dir) == False:\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    out_nodes = []\n",
    "\n",
    "    for i in range(len(keras_model.outputs)):\n",
    "        out_nodes.append(out_prefix + str(i + 1))\n",
    "        tf.identity(keras_model.output[i], \n",
    "            out_prefix + str(i + 1))\n",
    "\n",
    "    sess = K.get_session()\n",
    "\n",
    "\n",
    "    init_graph = sess.graph.as_graph_def()\n",
    "\n",
    "    main_graph = graph_util.convert_variables_to_constants(\n",
    "            sess, init_graph, out_nodes)\n",
    "\n",
    "    graph_io.write_graph(main_graph, output_dir, \n",
    "        name=model_name, as_text=False)\n",
    "\n",
    "    if log_tensorboard:\n",
    "        import_pb_to_tensorboard.import_to_tensorboard(\n",
    "            os.path.join(output_dir, model_name),\n",
    "            output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 318 variables.\n",
      "INFO:tensorflow:Converted 318 variables to const ops.\n",
      "Model Imported. Visualize by running: tensorboard --logdir=android\n",
      "INFO:tensorflow:Froze 318 variables.\n",
      "INFO:tensorflow:Converted 318 variables to const ops.\n",
      "Model Imported. Visualize by running: tensorboard --logdir=android\n"
     ]
    }
   ],
   "source": [
    "## save both models\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "keras_to_tensorflow(base_resnet, 'android', 'base_resnet_model.pb')\n",
    "keras_to_tensorflow(last_layers_model, 'android', 'last_layers_model.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IOS Core ML (work-in-progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'coremltools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e9839d0ee9b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcoremltools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msaveCoreMLModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     coreml_model = coremltools.converters.keras.convert(model,\n\u001b[1;32m      5\u001b[0m     \u001b[0minput_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'probs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'coremltools'"
     ]
    }
   ],
   "source": [
    "import coremltools\n",
    "\n",
    "def saveCoreMLModel(model):\n",
    "    coreml_model = coremltools.converters.keras.convert(model,\n",
    "    input_names=['input'], output_names=['probs'],\n",
    "        image_input_names='input',\n",
    "        predicted_feature_name='dogBreed',\n",
    "        class_labels='') ## fix\n",
    "    coreml_model.save('resnet50custom.mlmodel')\n",
    "    print('coreml saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dog-project",
   "language": "python",
   "name": "dog-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
